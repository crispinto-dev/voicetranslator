<!DOCTYPE html>
<html lang="it">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Guida - Dual Device Mode</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      padding: 20px;
    }

    .container {
      background: white;
      border-radius: 20px;
      box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
      padding: 40px;
      max-width: 600px;
      width: 100%;
    }

    h1 {
      color: #333;
      margin-bottom: 10px;
      font-size: 28px;
      text-align: center;
    }

    .subtitle {
      color: #666;
      text-align: center;
      margin-bottom: 30px;
      font-size: 14px;
    }

    .info-box {
      background: #fef3c7;
      border-left: 4px solid #f59e0b;
      padding: 15px;
      margin-bottom: 25px;
      border-radius: 8px;
      font-size: 13px;
      color: #92400e;
      line-height: 1.6;
    }

    .form-group {
      margin-bottom: 20px;
    }

    label {
      display: block;
      color: #555;
      font-weight: 500;
      margin-bottom: 8px;
      font-size: 14px;
    }

    select {
      width: 100%;
      padding: 12px 16px;
      border: 2px solid #e0e0e0;
      border-radius: 10px;
      font-size: 16px;
      background: white;
    }

    select:focus {
      outline: none;
      border-color: #f59e0b;
    }

    .btn {
      width: 100%;
      padding: 14px;
      border: none;
      border-radius: 10px;
      font-size: 16px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.3s;
      margin-top: 10px;
    }

    .btn-primary {
      background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
      color: white;
    }

    .btn-primary:hover:not(:disabled) {
      transform: translateY(-2px);
      box-shadow: 0 6px 20px rgba(245, 158, 11, 0.4);
    }

    .btn-primary:disabled {
      background: #d1d5db;
      cursor: not-allowed;
    }

    .btn-danger {
      background: #ef4444;
      color: white;
    }

    .btn-danger:hover {
      background: #dc2626;
    }

    .status {
      text-align: center;
      padding: 12px;
      border-radius: 10px;
      margin-top: 20px;
      font-size: 14px;
      font-weight: 500;
    }

    .status.inactive { background: #f3f4f6; color: #6b7280; }
    .status.connecting { background: #fef3c7; color: #92400e; }
    .status.active { background: #d1fae5; color: #065f46; }
    .status.listening { background: #dbeafe; color: #1e40af; }

    .hidden { display: none; }

    .stats {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 10px;
      margin-top: 20px;
    }

    .stat-box {
      background: #f9fafb;
      padding: 12px;
      border-radius: 8px;
      text-align: center;
    }

    .stat-label {
      font-size: 11px;
      color: #6b7280;
      text-transform: uppercase;
      margin-bottom: 5px;
    }

    .stat-value {
      font-size: 20px;
      font-weight: 600;
      color: #f59e0b;
    }

    .transcript {
      margin-top: 20px;
      padding: 15px;
      background: #f9fafb;
      border-radius: 10px;
      max-height: 200px;
      overflow-y: auto;
    }

    .transcript h3 {
      font-size: 12px;
      color: #6b7280;
      margin-bottom: 10px;
      text-transform: uppercase;
    }

    .transcript p {
      font-size: 13px;
      color: #333;
      line-height: 1.6;
      margin: 5px 0;
      padding: 8px;
      background: white;
      border-radius: 6px;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>üé§ Guida - Input</h1>
    <p class="subtitle">Dual Device Mode - Device Guida</p>

    <div class="info-box">
      <strong>‚ö†Ô∏è Importante:</strong> Questa √® la pagina per la GUIDA.<br>
      ‚Ä¢ Tu parli in <strong>italiano</strong> (o la tua lingua)<br>
      ‚Ä¢ Seleziona la lingua in cui <strong>tradurre</strong> (es. English)<br>
      ‚Ä¢ Sul device ricevitore, apri <strong>/visitor.html</strong> con la stessa lingua
    </div>

    <div id="setupForm">
      <div class="form-group">
        <label for="targetLanguage">üåç Traduci in:</label>
        <select id="targetLanguage">
          <option value="en">English</option>
          <option value="es">Espa√±ol</option>
          <option value="fr">Fran√ßais</option>
          <option value="de">Deutsch</option>
          <option value="pt">Portugu√™s</option>
          <option value="zh">‰∏≠Êñá</option>
          <option value="ja">Êó•Êú¨Ë™û</option>
          <option value="ko">ÌïúÍµ≠Ïñ¥</option>
          <option value="ar">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</option>
          <option value="ru">–†—É—Å—Å–∫–∏–π</option>
        </select>
      </div>

      <button class="btn btn-primary" id="startBtn">
        Avvia Modalit√† Guida
      </button>
    </div>

    <div id="activeSession" class="hidden">
      <div class="status inactive" id="status">Inattivo</div>

      <div class="stats">
        <div class="stat-box">
          <div class="stat-label">Chunk Inviati</div>
          <div class="stat-value" id="chunksSent">0</div>
        </div>
        <div class="stat-box">
          <div class="stat-label">Ricevitore</div>
          <div class="stat-value" id="receiverStatus">üî¥</div>
        </div>
      </div>

      <div class="transcript">
        <h3>Traduzione Inviata</h3>
        <div id="transcriptLog"></div>
      </div>

      <button class="btn btn-danger" id="stopBtn">
        Termina Sessione
      </button>
    </div>
  </div>

  <script type="module">
    import { RealtimeAgent, RealtimeSession } from '@openai/agents-realtime';

    class GuideInput {
      constructor() {
        this.session = null;
        this.agent = null;
        this.isRunning = false;
        this.targetLanguage = 'en';
        this.chunksSent = 0;
        this.sequenceNumber = 0;
        this.pendingText = '';
        this.lastSendTime = 0;

        this.initializeUI();
      }

      initializeUI() {
        this.setupForm = document.getElementById('setupForm');
        this.activeSession = document.getElementById('activeSession');
        this.status = document.getElementById('status');
        this.chunksSentEl = document.getElementById('chunksSent');
        this.receiverStatusEl = document.getElementById('receiverStatus');
        this.transcriptLog = document.getElementById('transcriptLog');
        this.targetLanguageSelect = document.getElementById('targetLanguage');
        this.startBtn = document.getElementById('startBtn');
        this.stopBtn = document.getElementById('stopBtn');

        this.startBtn.addEventListener('click', () => this.start());
        this.stopBtn.addEventListener('click', () => this.stop());
      }

      async start() {
        try {
          this.targetLanguage = this.targetLanguageSelect.value;
          this.startBtn.disabled = true;
          this.updateStatus('connecting', '‚è≥ Connessione...');

          // Get token
          const tokenResponse = await fetch('/api/realtime/token', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              language: this.targetLanguage,
              mode: 'museum'
            })
          });

          if (!tokenResponse.ok) {
            throw new Error('Failed to get token');
          }

          const { token, instructions } = await tokenResponse.json();
          console.log('[Guide] Token received');

          // Create agent
          this.agent = new RealtimeAgent({
            name: 'GuideTranslator',
            instructions: instructions
          });

          // Create session with auto response on VAD and output transcription
          const sessionConfig = {
            model: 'gpt-4o-realtime-preview-2024-12-17',
            // Use audio modality with transcription
            inputAudioTranscription: { model: 'whisper-1' },
            config: {
              turnDetection: {
                type: 'server_vad',
                threshold: 0.5,
                prefixPaddingMs: 300,
                silenceDurationMs: 700,
                createResponse: true,       // Auto-create response on speech end
                interruptResponse: false    // No interruption
              }
            }
          };

          this.session = new RealtimeSession(this.agent, sessionConfig);
          this.setupEventHandlers();

          // Connect
          await this.session.connect({ apiKey: token });
          console.log('[Guide] Connected to OpenAI Realtime API');

          // Configure session for TEXT ONLY output (no audio needed on guide side)
          setTimeout(() => {
            if (this.session?.transport?.send) {
              const updatePayload = {
                type: 'session.update',
                session: {
                  modalities: ['text']  // TEXT ONLY - no TTS needed on guide side
                }
              };
              console.log('[Guide] Sending session.update:', JSON.stringify(updatePayload));
              this.session.transport.send(updatePayload);
            }
          }, 200);

          // Mute any audio elements created by SDK (it ignores modalities setting)
          this.muteAllAudio();
          setInterval(() => this.muteAllAudio(), 500);

          this.updateStatus('active', '‚úÖ Attivo - Parla nel microfono');
          this.setupForm.classList.add('hidden');
          this.activeSession.classList.remove('hidden');
          this.isRunning = true;

        } catch (error) {
          console.error('[Guide] Error:', error);
          this.updateStatus('inactive', '‚ùå Errore: ' + error.message);
          this.startBtn.disabled = false;
          alert('Errore nella connessione. Riprova.');
        }
      }

      async stop() {
        if (this.session) {
          await this.session.disconnect();
          this.session = null;
          this.agent = null;
        }

        this.setupForm.classList.remove('hidden');
        this.activeSession.classList.add('hidden');
        this.startBtn.disabled = false;
        this.isRunning = false;
        this.chunksSent = 0;
        this.sequenceNumber = 0;
        this.updateStatus('inactive', 'Terminato');
        this.transcriptLog.innerHTML = '';
      }

      setupEventHandlers() {
        if (!this.session) return;

        // Log ALL events from any source
        const logEvent = (source, event) => {
          const eventStr = JSON.stringify(event).substring(0, 300);
          console.log(`[${source}]`, event.type || event, eventStr);
        };

        // Try multiple event listeners to catch all events
        this.session.on('*', (event) => logEvent('Session *', event));
        this.session.on('message', (event) => logEvent('Session message', event));
        this.session.on('response', (event) => logEvent('Session response', event));

        this.session.on('transport_event', (event) => {
          logEvent('transport_event', event);

          switch (event.type) {
            case 'input_audio_buffer.speech_started':
              console.log('[Guide] Speech detected');
              this.updateStatus('listening', 'üé§ Rilevata voce');
              break;

            case 'input_audio_buffer.speech_stopped':
              console.log('[Guide] Speech stopped, triggering response');
              this.updateStatus('active', 'üîÑ Traduzione...');

              // Trigger manual response - TEXT ONLY (no TTS on guide side)
              setTimeout(() => {
                if (this.session?.transport?.send) {
                  const payload = {
                    type: 'response.create',
                    response: {
                      modalities: ['text']  // TEXT ONLY - faster, no audio generation
                    }
                  };
                  console.log('[Guide] Sending response.create via transport:', JSON.stringify(payload));
                  this.session.transport.send(payload);
                }
              }, 100);
              break;

            // Primary text events (ideal case)
            case 'response.text.delta':
              console.log('[Guide] ‚úÖ Text delta:', event.delta);
              if (event.delta) {
                this.pendingText += event.delta;
                this.considerSendingChunk(false);
              }
              break;

            case 'response.text.done':
              console.log('[Guide] ‚úÖ Text done:', event.text);
              if (event.text) {
                this.pendingText = event.text;
                this.considerSendingChunk(true);
              }
              break;

            // Fallback: audio_transcript events (SDK might use these instead)
            case 'response.audio_transcript.delta':
              console.log('[Guide] üîÑ Fallback audio_transcript.delta:', event.delta);
              if (event.delta) {
                this.pendingText += event.delta;
                this.considerSendingChunk(false);
              }
              break;

            case 'response.audio_transcript.done':
              console.log('[Guide] üîÑ Fallback audio_transcript.done:', event.transcript);
              if (event.transcript) {
                this.pendingText = event.transcript;
                this.considerSendingChunk(true);
              }
              break;

            // Alternative: conversation.item with text content
            case 'conversation.item.created':
              if (event.item?.role === 'assistant') {
                console.log('[Guide] üîÑ Fallback conversation.item.created');
                const textContent = event.item.content?.find(c => c.type === 'text');
                if (textContent?.text) {
                  console.log('[Guide] Found text in conversation item:', textContent.text);
                  this.pendingText += textContent.text;
                  this.considerSendingChunk(false);
                }
                // Also check for transcript in audio content
                const audioContent = event.item.content?.find(c => c.type === 'audio');
                if (audioContent?.transcript) {
                  console.log('[Guide] Found transcript in audio content:', audioContent.transcript);
                  this.pendingText += audioContent.transcript;
                  this.considerSendingChunk(false);
                }
              }
              break;

            // Response output item events
            case 'response.output_item.added':
            case 'response.output_item.done':
              console.log('[Guide] üîÑ Output item event:', event.type);
              if (event.item) {
                const textContent = event.item.content?.find(c => c.type === 'text');
                if (textContent?.text) {
                  console.log('[Guide] Found text in output item:', textContent.text);
                  this.pendingText += textContent.text;
                  this.considerSendingChunk(event.type.includes('done'));
                }
                const audioContent = event.item.content?.find(c => c.type === 'audio');
                if (audioContent?.transcript) {
                  console.log('[Guide] Found transcript in output audio:', audioContent.transcript);
                  this.pendingText += audioContent.transcript;
                  this.considerSendingChunk(event.type.includes('done'));
                }
              }
              break;

            // Response content part events
            case 'response.content_part.added':
            case 'response.content_part.done':
              console.log('[Guide] üîÑ Content part event:', event.type, event.part);
              if (event.part?.text) {
                this.pendingText += event.part.text;
                this.considerSendingChunk(event.type.includes('done'));
              }
              if (event.part?.transcript) {
                this.pendingText += event.part.transcript;
                this.considerSendingChunk(event.type.includes('done'));
              }
              break;

            case 'response.created':
              console.log('[Guide] ‚úÖ Response CREATED - response generation started');
              break;

            case 'response.done':
              console.log('[Guide] Response complete, pending text:', this.pendingText);
              // Log full response details if available
              if (event.response) {
                console.log('[Guide] Response details:', JSON.stringify(event.response).substring(0, 500));
              }
              this.considerSendingChunk(true); // Force send any remaining
              this.updateStatus('active', '‚úÖ Pronto');
              break;

            case 'error':
              console.error('[Guide] ‚ùå Error:', event.error);
              break;
          }
        });
      }

      considerSendingChunk(force = false) {
        const now = Date.now();
        const timeSinceLastSend = now - this.lastSendTime;
        const shouldSend = force ||
                          (this.pendingText.length >= 140 && timeSinceLastSend >= 800) ||
                          (this.pendingText.length >= 80 && timeSinceLastSend >= 1200);

        if (shouldSend && this.pendingText.trim()) {
          this.sendChunk(this.pendingText.trim());
          this.pendingText = '';
          this.lastSendTime = now;
        }
      }

      async sendChunk(text) {
        if (!text) return;

        const chunk = {
          lang: this.targetLanguage,  // CRITICAL: tell backend which language this is
          text: text,
          ts: Date.now(),
          seq: ++this.sequenceNumber
        };

        console.log(`[Guide] Sending chunk #${chunk.seq} (lang: ${chunk.lang}):`, text.substring(0, 50) + '...');

        try {
          const response = await fetch('/ingest', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(chunk)
          });

          const result = await response.json();

          if (result.ok) {
            this.chunksSent++;
            this.chunksSentEl.textContent = this.chunksSent;
            this.receiverStatusEl.textContent = result.hasReceiver ? 'üü¢' : 'üî¥';
            this.addToTranscript(text);
          }
        } catch (error) {
          console.error('[Guide] Error sending chunk:', error);
        }
      }

      addToTranscript(text) {
        const p = document.createElement('p');
        p.textContent = text;
        this.transcriptLog.prepend(p);

        // Keep only last 10 items
        while (this.transcriptLog.children.length > 10) {
          this.transcriptLog.removeChild(this.transcriptLog.lastChild);
        }
      }

      updateStatus(state, text) {
        this.status.className = 'status ' + state;
        this.status.textContent = text;
      }

      muteAllAudio() {
        // Mute ALL audio elements on page (SDK creates them dynamically)
        document.querySelectorAll('audio').forEach(audio => {
          audio.volume = 0;
          audio.muted = true;
          audio.pause();
        });
        // Also intercept any new audio context
        if (window.AudioContext || window.webkitAudioContext) {
          const OriginalAudioContext = window.AudioContext || window.webkitAudioContext;
          if (!window._audioContextPatched) {
            window._audioContextPatched = true;
            const patchedContext = function(...args) {
              const ctx = new OriginalAudioContext(...args);
              // Create a gain node set to 0 to mute
              const gainNode = ctx.createGain();
              gainNode.gain.value = 0;
              const originalConnect = ctx.destination;
              // Intercept connections to destination
              return ctx;
            };
            // Don't override - just mute elements
          }
        }
      }
    }

    // Initialize
    const guide = new GuideInput();
  </script>
</body>
</html>
