<!DOCTYPE html>
<html lang="it">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Guida - Dual Device Mode</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      padding: 20px;
    }

    .container {
      background: white;
      border-radius: 20px;
      box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
      padding: 40px;
      max-width: 600px;
      width: 100%;
    }

    h1 {
      color: #333;
      margin-bottom: 10px;
      font-size: 28px;
      text-align: center;
    }

    .subtitle {
      color: #666;
      text-align: center;
      margin-bottom: 30px;
      font-size: 14px;
    }

    .info-box {
      background: #fef3c7;
      border-left: 4px solid #f59e0b;
      padding: 15px;
      margin-bottom: 25px;
      border-radius: 8px;
      font-size: 13px;
      color: #92400e;
      line-height: 1.6;
    }

    .form-group {
      margin-bottom: 20px;
    }

    label {
      display: block;
      color: #555;
      font-weight: 500;
      margin-bottom: 8px;
      font-size: 14px;
    }

    select {
      width: 100%;
      padding: 12px 16px;
      border: 2px solid #e0e0e0;
      border-radius: 10px;
      font-size: 16px;
      background: white;
    }

    select:focus {
      outline: none;
      border-color: #f59e0b;
    }

    .btn {
      width: 100%;
      padding: 14px;
      border: none;
      border-radius: 10px;
      font-size: 16px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.3s;
      margin-top: 10px;
    }

    .btn-primary {
      background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
      color: white;
    }

    .btn-primary:hover:not(:disabled) {
      transform: translateY(-2px);
      box-shadow: 0 6px 20px rgba(245, 158, 11, 0.4);
    }

    .btn-primary:disabled {
      background: #d1d5db;
      cursor: not-allowed;
    }

    .btn-danger {
      background: #ef4444;
      color: white;
    }

    .btn-danger:hover {
      background: #dc2626;
    }

    .status {
      text-align: center;
      padding: 12px;
      border-radius: 10px;
      margin-top: 20px;
      font-size: 14px;
      font-weight: 500;
    }

    .status.inactive { background: #f3f4f6; color: #6b7280; }
    .status.connecting { background: #fef3c7; color: #92400e; }
    .status.active { background: #d1fae5; color: #065f46; }
    .status.listening { background: #dbeafe; color: #1e40af; }

    .hidden { display: none; }

    .preset-selector {
      display: flex;
      gap: 8px;
      margin-top: 8px;
    }

    .preset-option {
      flex: 1;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 10px 8px;
      border: 2px solid #e0e0e0;
      border-radius: 10px;
      cursor: pointer;
      transition: all 0.2s;
      background: white;
    }

    .preset-option:hover {
      border-color: #f59e0b;
    }

    .preset-option input {
      display: none;
    }

    .preset-option input:checked + .preset-label {
      font-weight: 700;
    }

    .preset-option:has(input:checked) {
      border-color: #f59e0b;
      background: #fef3c7;
    }

    .preset-label {
      font-size: 13px;
      font-weight: 500;
      color: #333;
    }

    .preset-desc {
      font-size: 10px;
      color: #888;
      margin-top: 2px;
    }

    .preset-hint {
      font-size: 11px;
      color: #888;
      text-align: center;
      margin-top: 8px;
    }

    .wake-lock-badge {
      text-align: center;
      font-size: 12px;
      color: #065f46;
      background: #d1fae5;
      padding: 6px 12px;
      border-radius: 8px;
      margin-top: 10px;
    }

    .mic-group {
      display: flex;
      gap: 8px;
      align-items: center;
    }

    .mic-group select {
      flex: 1;
    }

    .mic-refresh {
      padding: 10px 14px;
      border: 2px solid #e0e0e0;
      border-radius: 10px;
      background: white;
      cursor: pointer;
      font-size: 16px;
      line-height: 1;
    }

    .mic-refresh:hover {
      border-color: #f59e0b;
    }

    .stats {
      display: grid;
      grid-template-columns: 1fr 1fr 1fr;
      gap: 10px;
      margin-top: 20px;
    }

    .stat-box {
      background: #f9fafb;
      padding: 12px;
      border-radius: 8px;
      text-align: center;
    }

    .stat-label {
      font-size: 11px;
      color: #6b7280;
      text-transform: uppercase;
      margin-bottom: 5px;
    }

    .stat-value {
      font-size: 20px;
      font-weight: 600;
      color: #f59e0b;
    }

    .transcript {
      margin-top: 20px;
      padding: 15px;
      background: #f9fafb;
      border-radius: 10px;
      max-height: 200px;
      overflow-y: auto;
    }

    .transcript h3 {
      font-size: 12px;
      color: #6b7280;
      margin-bottom: 10px;
      text-transform: uppercase;
    }

    .transcript p {
      font-size: 13px;
      color: #333;
      line-height: 1.6;
      margin: 5px 0;
      padding: 8px;
      background: white;
      border-radius: 6px;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>üé§ Guida - Input</h1>
    <p class="subtitle">Dual Device Mode - Device Guida</p>

    <div class="info-box">
      <strong>‚ö†Ô∏è Importante:</strong> Questa √® la pagina per la GUIDA.<br>
      ‚Ä¢ Tu parli in <strong>italiano</strong> (o la tua lingua)<br>
      ‚Ä¢ Seleziona la lingua in cui <strong>tradurre</strong> (es. English)<br>
      ‚Ä¢ Sul device ricevitore, apri <strong>/visitor.html</strong> con la stessa lingua
    </div>

    <div id="setupForm">
      <div class="form-group">
        <label for="targetLanguage">üåç Traduci in:</label>
        <select id="targetLanguage">
          <option value="en">English</option>
          <option value="es">Espa√±ol</option>
          <option value="fr">Fran√ßais</option>
          <option value="de">Deutsch</option>
          <option value="pt">Portugu√™s</option>
          <option value="zh">‰∏≠Êñá</option>
          <option value="ja">Êó•Êú¨Ë™û</option>
          <option value="ko">ÌïúÍµ≠Ïñ¥</option>
          <option value="ar">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</option>
          <option value="ru">–†—É—Å—Å–∫–∏–π</option>
        </select>
      </div>

      <div class="form-group">
        <label>‚ö° Stile traduzione:</label>
        <div class="preset-selector">
          <label class="preset-option">
            <input type="radio" name="preset" value="simultaneous" checked>
            <span class="preset-label">üü¢ Simultaneo</span>
            <span class="preset-desc">Rapido</span>
          </label>
          <label class="preset-option">
            <input type="radio" name="preset" value="balanced">
            <span class="preset-label">‚ö™ Equilibrato</span>
            <span class="preset-desc">Compromesso</span>
          </label>
          <label class="preset-option">
            <input type="radio" name="preset" value="natural">
            <span class="preset-label">üîµ Naturale</span>
            <span class="preset-desc">Frasi complete</span>
          </label>
        </div>
        <p class="preset-hint">Pi√π veloce ‚Üí meno ritardo | Pi√π naturale ‚Üí frasi pi√π complete</p>
      </div>

      <div class="form-group">
        <label for="micSelect">üé§ Microfono:</label>
        <div class="mic-group">
          <select id="micSelect"><option value="">Default del sistema</option></select>
          <button type="button" class="mic-refresh" id="micRefresh" title="Aggiorna lista">üîÑ</button>
        </div>
      </div>

      <button class="btn btn-primary" id="startBtn">
        Avvia Modalit√† Guida
      </button>
    </div>

    <div id="activeSession" class="hidden">
      <div class="status inactive" id="status">Inattivo</div>
      <div class="wake-lock-badge" id="wakeLockBadge" style="display:none">üîí Schermo attivo</div>

      <div class="stats">
        <div class="stat-box">
          <div class="stat-label">Chunk Inviati</div>
          <div class="stat-value" id="chunksSent">0</div>
        </div>
        <div class="stat-box">
          <div class="stat-label">Ricevitore</div>
          <div class="stat-value" id="receiverStatus">üî¥</div>
        </div>
        <div class="stat-box">
          <div class="stat-label">Ritardo</div>
          <div class="stat-value" id="latencyDisplay">--</div>
        </div>
      </div>

      <div class="transcript">
        <h3>Testo Rilevato (IT)</h3>
        <div id="transcriptLog"></div>
      </div>

      <button class="btn btn-danger" id="stopBtn">
        Termina Sessione
      </button>
    </div>
  </div>

  <script type="module">
    import { RealtimeAgent, RealtimeSession } from '@openai/agents-realtime';

    // Translation style presets
    const PRESETS = {
      simultaneous: {
        name: 'Simultaneo',
        MICRO_MAX_CHARS: 100,
        MICRO_MIN_CHARS: 20,
        MICRO_FLUSH_MS: 650,
        MIN_SEND_GAP_MS: 200,
        STT_PAUSE_MS: 450
      },
      balanced: {
        name: 'Equilibrato',
        MICRO_MAX_CHARS: 140,
        MICRO_MIN_CHARS: 35,
        MICRO_FLUSH_MS: 900,
        MIN_SEND_GAP_MS: 280,
        STT_PAUSE_MS: 600
      },
      natural: {
        name: 'Naturale',
        MICRO_MAX_CHARS: 200,
        MICRO_MIN_CHARS: 50,
        MICRO_FLUSH_MS: 1400,
        MIN_SEND_GAP_MS: 350,
        STT_PAUSE_MS: 800
      }
    };

    class GuideInput {
      constructor() {
        this.session = null;
        this.agent = null;
        this.isRunning = false;
        this.targetLanguage = 'en';
        this.chunksSent = 0;
        this.sequenceNumber = 0;

        // Micro-chunking state - initialized from preset
        this.microBuffer = '';
        this.microFlushTimer = null;    // for scheduleMicroFlush
        this.speechStoppedTimer = null; // for speech_stopped delayed flush
        this.muteInterval = null;
        this.currentPreset = 'simultaneous';
        this.applyPreset(this.currentPreset);

        // Dedup state (avoid STT repeating same phrase)
        this.lastSentText = '';
        this.lastSentAt = 0;

        // Anti-burst: minimum gap between sends
        this.lastSendAt = 0;

        // Wake lock
        this.wakeLock = null;

        // Delta transcript tracking (forward-compatible)
        this.gotDelta = false;

        // Latency tracking (P7)
        this.chunkLatencies = [];
        this.latencyDisplayEl = null;

        // STT activity tracking for pause flush (P5)
        this.lastSttActivityTime = Date.now();
        this.sttPauseInterval = null;

        // Mic stream reference for explicit cleanup on stop (E)
        this.micStream = null;
        // Guard against infinite reconnect loop (A)
        this._micRetry = false;

        this.initializeUI();
      }

      applyPreset(presetName) {
        const preset = PRESETS[presetName] || PRESETS.simultaneous;
        this.currentPreset = presetName;
        this.MICRO_MAX_CHARS = preset.MICRO_MAX_CHARS;
        this.MICRO_MIN_CHARS = preset.MICRO_MIN_CHARS;
        this.MICRO_FLUSH_MS = preset.MICRO_FLUSH_MS;
        this.MIN_SEND_GAP_MS = preset.MIN_SEND_GAP_MS;
        this.STT_PAUSE_MS = preset.STT_PAUSE_MS;
        console.log(`[Guide] Applied preset: ${preset.name}`, preset);
      }

      initializeUI() {
        this.setupForm = document.getElementById('setupForm');
        this.activeSession = document.getElementById('activeSession');
        this.status = document.getElementById('status');
        this.chunksSentEl = document.getElementById('chunksSent');
        this.receiverStatusEl = document.getElementById('receiverStatus');
        this.transcriptLog = document.getElementById('transcriptLog');
        this.targetLanguageSelect = document.getElementById('targetLanguage');
        this.startBtn = document.getElementById('startBtn');
        this.stopBtn = document.getElementById('stopBtn');

        this.micSelect = document.getElementById('micSelect');
        this.micRefresh = document.getElementById('micRefresh');
        this.wakeLockBadge = document.getElementById('wakeLockBadge');
        this.latencyDisplayEl = document.getElementById('latencyDisplay');

        this.startBtn.addEventListener('click', () => this.start());
        this.stopBtn.addEventListener('click', () => this.stop());
        this.micRefresh.addEventListener('click', () => this.enumerateMics());
        this.enumerateMics();

        // Reactivate wake lock when tab becomes visible again
        document.addEventListener('visibilitychange', async () => {
          if (document.visibilityState === 'visible' && this.isRunning && !this.wakeLock) {
            await this.requestWakeLock();
          }
        });
      }

      async start() {
        try {
          this.targetLanguage = this.targetLanguageSelect.value;

          // Apply selected preset
          const selectedPreset = document.querySelector('input[name="preset"]:checked')?.value || 'simultaneous';
          this.applyPreset(selectedPreset);

          this.startBtn.disabled = true;
          this.updateStatus('connecting', '‚è≥ Connessione...');

          // Pre-acquire microphone with anti-noise constraints (before connect for Android stability)
          const selectedMic = this.micSelect?.value;
          const audioConstraints = {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          };
          if (selectedMic) audioConstraints.deviceId = { exact: selectedMic };
          try {
            this.micStream = await navigator.mediaDevices.getUserMedia({ audio: audioConstraints });
            console.log('[Guide] Pre-acquired mic:', this.micStream.getAudioTracks()[0]?.label);
          } catch (e) {
            console.warn('[Guide] Could not pre-acquire mic:', e);
            this.micStream = null;
          }

          // Get token for STT only
          const tokenResponse = await fetch('/api/realtime/token', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              language: this.targetLanguage,
              mode: 'stt-only'  // New mode: STT only, no translation
            })
          });

          if (!tokenResponse.ok) {
            throw new Error('Failed to get token');
          }

          const { token } = await tokenResponse.json();
          console.log('[Guide] Token received');

          // Create agent with minimal instructions (STT only)
          this.agent = new RealtimeAgent({
            name: 'GuideSTT',
            instructions: 'You are a speech-to-text transcriber. Just listen.'
          });

          // Create session for STT only - NO response generation
          const sessionConfig = {
            model: 'gpt-4o-realtime-preview-2024-12-17',
            inputAudioTranscription: { model: 'whisper-1' },
            config: {
              turnDetection: {
                type: 'server_vad',
                threshold: 0.45,          // Slightly lower to catch speech starts
                prefixPaddingMs: 300,
                silenceDurationMs: 750,   // Lowered for noisy environments
                createResponse: false,    // NO response - STT only
                interruptResponse: false
              }
            }
          };

          this.session = new RealtimeSession(this.agent, sessionConfig);
          this.setupEventHandlers();

          // Connect
          await this.session.connect({ apiKey: token });
          console.log('[Guide] Connected to OpenAI Realtime API (STT mode)');

          // Mute any audio elements (shouldn't be any, but just in case)
          this.muteAllAudio();
          this.muteInterval = setInterval(() => this.muteAllAudio(), 500);

          // Apply pre-acquired mic to WebRTC, with reconnect fallback if replaceTrack fails
          await this.applyMicToWebRTC();
          this._micRetry = false;

          this.updateStatus('active', '‚úÖ Attivo - Parla nel microfono');
          this.setupForm.classList.add('hidden');
          this.activeSession.classList.remove('hidden');
          this.isRunning = true;

          // Request wake lock to keep screen on
          await this.requestWakeLock();

          // Start STT pause flush (P5: flush buffer on 450ms silence in simultaneous mode)
          this.lastSttActivityTime = Date.now();
          if (this.sttPauseInterval) clearInterval(this.sttPauseInterval);
          this.sttPauseInterval = setInterval(() => {
            const silenceMs = Date.now() - this.lastSttActivityTime;
            if (silenceMs > this.STT_PAUSE_MS && this.microBuffer.trim().length > 0) {
              this.flushMicroBuffer('stt_pause');
            }
          }, 100);

        } catch (error) {
          console.error('[Guide] Error:', error);
          this.updateStatus('inactive', '‚ùå Errore: ' + error.message);
          this.startBtn.disabled = false;
          alert('Errore nella connessione. Riprova.');
        }
      }

      async stop() {
        console.log('[Guide] Stopping session...');

        // First: stop all timers and intervals
        if (this.microFlushTimer) { clearTimeout(this.microFlushTimer); this.microFlushTimer = null; }
        if (this.speechStoppedTimer) { clearTimeout(this.speechStoppedTimer); this.speechStoppedTimer = null; }
        if (this.sttPauseInterval) { clearInterval(this.sttPauseInterval); this.sttPauseInterval = null; }
        if (this.muteInterval) { clearInterval(this.muteInterval); this.muteInterval = null; }
        this.microBuffer = '';

        // Disconnect session with timeout (some devices can hang on disconnect)
        if (this.session) {
          try {
            await Promise.race([
              this.session.disconnect(),
              new Promise((_, reject) => setTimeout(() => reject(new Error('timeout')), 5000))
            ]);
          } catch (err) {
            console.warn('[Guide] Disconnect failed or timed out:', err.message);
          }
          this.session = null;
          this.agent = null;
        }

        // Always stop mic stream (even if disconnect failed)
        if (this.micStream) {
          this.micStream.getTracks().forEach(t => {
            t.stop();
            console.log('[Guide] Mic track stopped:', t.label);
          });
          this.micStream = null;
        }

        // Release wake lock
        await this.releaseWakeLock();

        this.setupForm.classList.remove('hidden');
        this.activeSession.classList.add('hidden');
        this.startBtn.disabled = false;
        this.isRunning = false;
        this.chunksSent = 0;
        this.sequenceNumber = 0;
        this.updateStatus('inactive', 'Terminato');
        this.transcriptLog.innerHTML = '';
        console.log('[Guide] Session stopped');
      }

      setupEventHandlers() {
        if (!this.session) return;

        this.session.on('transport_event', (event) => {
          // Log for debugging
          if (event.type?.includes('transcription') || event.type?.includes('speech')) {
            console.log('[Guide Event]', event.type, JSON.stringify(event).substring(0, 200));
          }

          switch (event.type) {
            case 'input_audio_buffer.speech_started':
              console.log('[Guide] üé§ Speech detected');
              this.lastSttActivityTime = Date.now();
              this.updateStatus('listening', 'üé§ Rilevata voce...');
              break;

            case 'input_audio_buffer.speech_stopped':
              console.log('[Guide] Speech stopped, waiting for transcription...');
              this.updateStatus('active', 'üîÑ Trascrizione...');
              // Delayed flush: wait for transcription.completed to arrive first
              if (this.speechStoppedTimer) clearTimeout(this.speechStoppedTimer);
              this.speechStoppedTimer = setTimeout(() => {
                this.flushMicroBuffer('speech_stopped_delayed');
              }, 300);
              break;

            // Delta transcript (forward-compatible: if API adds streaming input transcription)
            case 'conversation.item.input_audio_transcription.delta': {
              const deltaText = (event.delta || '').trim();
              if (deltaText) {
                this.lastSttActivityTime = Date.now();
                this.gotDelta = true;
                console.log('[Guide] üìù STT delta:', deltaText);
                this.microBuffer = (this.microBuffer || '') + deltaText;
                if (this.microBuffer.length >= this.MICRO_MAX_CHARS) {
                  this.flushMicroBuffer('delta_max');
                } else {
                  this.scheduleMicroFlush();
                }
              }
              break;
            }

            // Complete transcription: buffer for micro-chunking
            case 'conversation.item.input_audio_transcription.completed': {
              this.lastSttActivityTime = Date.now();
              const itText = (event.transcript || '').trim();
              console.log('[Guide] üìù STT completed:', itText);

              if (this.gotDelta) {
                // Already processed via deltas - just flush on strong punctuation
                this.gotDelta = false;
                if (/[.!?]$/.test(itText) && this.microBuffer) {
                  this.flushMicroBuffer('punct_after_delta');
                }
              } else if (itText) {
                // No deltas - use completed text as before
                this.microBuffer = (this.microBuffer ? (this.microBuffer + ' ') : '') + itText;
                const endsStrong = /[.!?]$/.test(itText);
                if (endsStrong || this.microBuffer.length >= this.MICRO_MAX_CHARS) {
                  this.flushMicroBuffer(endsStrong ? 'punct' : 'max_chars');
                } else {
                  this.scheduleMicroFlush();
                }
              }

              this.updateStatus('active', '‚úÖ Pronto');
              break;
            }

            case 'error':
              console.error('[Guide] ‚ùå Error:', event.error);
              break;
          }
        });
      }

      // ==========================================
      // MICRO-CHUNKING FUNCTIONS
      // ==========================================

      scheduleMicroFlush() {
        if (this.microFlushTimer) clearTimeout(this.microFlushTimer);
        this.microFlushTimer = setTimeout(() => {
          this.flushMicroBuffer('timer');
        }, this.MICRO_FLUSH_MS);
      }

      splitIntoMicroChunks(text) {
        // Split on strong punctuation, keeping the punctuation with the sentence
        const parts = text
          .replace(/\s+/g, ' ')
          .split(/(?<=[\.\!\?\:\;])\s+/)
          .map(s => s.trim())
          .filter(Boolean);
        return parts;
      }

      flushMicroBuffer(reason = 'manual') {
        const buf = (this.microBuffer || '').trim();
        if (!buf) return;

        // If too short and doesn't end with strong punctuation, wait more
        const endsStrong = /[.!?]$/.test(buf);
        if (!endsStrong && buf.length < this.MICRO_MIN_CHARS) {
          this.scheduleMicroFlush();
          return;
        }

        // Avoid flushing on Italian connectives (sounds unnatural in TTS)
        const badEnding = /\b(e|ma|perch√©|quindi|che|di|a|da|in|con|su|per|tra|fra|un|una|il|lo|la|i|gli|le|al|del|nel|the|and|but|or|to|of)\s*$/i;
        if (!endsStrong && badEnding.test(buf) && buf.length < this.MICRO_MAX_CHARS) {
          console.log('[Guide] Bad ending, waiting for more text');
          this.scheduleMicroFlush();
          return;
        }

        // Split into micro-chunks
        const chunks = this.splitIntoMicroChunks(buf);

        if (chunks.length === 0) {
          this.sendSourceText(buf);
        } else {
          for (const c of chunks) {
            if (c.length >= 1) this.sendSourceText(c);
          }
        }

        this.microBuffer = '';
        if (this.microFlushTimer) {
          clearTimeout(this.microFlushTimer);
          this.microFlushTimer = null;
        }
        if (this.speechStoppedTimer) {
          clearTimeout(this.speechStoppedTimer);
          this.speechStoppedTimer = null;
        }

        console.log(`[Guide] Micro flush (${reason}): ${chunks.length} chunk(s)`);
      }

      // ==========================================
      // MICROPHONE ‚Üí WEBRTC (A)
      // ==========================================

      async applyMicToWebRTC() {
        if (!this.micStream) return;
        try {
          const pc = this.session?.transport?.pc || this.session?.pc || this.session?._pc;

          if (!pc) {
            console.error('[Guide] replaceTrack: PeerConnection non trovato');
            if (!this._micRetry) {
              this.updateStatus('connecting', 'üîÑ Riavvio per microfono esterno...');
              setTimeout(() => this._reconnectForMic(), 800);
            }
            return;
          }

          const newTrack = this.micStream.getAudioTracks()[0];
          const senders = pc.getSenders();
          const sender = senders.find(s => s.track?.kind === 'audio');

          // Diagnostic log BEFORE
          console.log('[Guide] === BEFORE replaceTrack ===');
          console.log('[Guide] All senders:', senders.map(s => ({ kind: s.track?.kind, label: s.track?.label, id: s.track?.id?.substring(0, 8) })));
          console.log('[Guide] Audio sender found:', sender?.track?.label ?? 'none');
          console.log('[Guide] New track to apply:', newTrack?.label ?? 'none');

          if (!sender) {
            console.error('[Guide] replaceTrack: nessun audio sender nel PC');
            if (!this._micRetry) {
              this.updateStatus('connecting', 'üîÑ Riavvio per microfono esterno...');
              setTimeout(() => this._reconnectForMic(), 800);
            }
            return;
          }

          await sender.replaceTrack(newTrack);

          // Diagnostic log AFTER
          const success = sender.track?.label === newTrack.label;
          console.log('[Guide] === AFTER replaceTrack ===');
          console.log('[Guide] Audio sender now:', sender.track?.label);
          console.log('[Guide] Track replaced successfully:', success);

          if (!success && !this._micRetry) {
            console.warn('[Guide] replaceTrack label mismatch, scheduling reconnect...');
            setTimeout(() => this._reconnectForMic(), 800);
          }
        } catch (e) {
          console.warn('[Guide] replaceTrack error:', e);
          if (!this._micRetry) {
            setTimeout(() => this._reconnectForMic(), 800);
          }
        }
      }

      async _reconnectForMic() {
        await this.stop();
        await new Promise(r => setTimeout(r, 500));
        this._micRetry = true;
        await this.start();
      }

      async sendSourceText(sourceText) {
        if (!sourceText) return;

        try {
          const now = Date.now();

          // Anti-burst: ensure minimum gap between sends
          const gap = now - this.lastSendAt;
          if (gap < this.MIN_SEND_GAP_MS) {
            setTimeout(() => this.sendSourceText(sourceText), this.MIN_SEND_GAP_MS - gap);
            return;
          }

          // Dedup: skip if same text was sent recently (STT sometimes repeats)
          const normalized = sourceText.replace(/\s+/g, ' ').trim().toLowerCase();
          if (normalized && normalized === this.lastSentText && (now - this.lastSentAt) < 2500) {
            console.log('[Guide] Dedup skip:', sourceText.substring(0, 30) + '...');
            return;
          }
          this.lastSentText = normalized;
          this.lastSendAt = now;

          const chunk = {
            lang: this.targetLanguage,
            sourceLang: 'it',
            sourceText: sourceText,
            ts: now,
            seq: ++this.sequenceNumber
          };

          console.log(`[Guide] Sending source chunk #${chunk.seq} -> ${chunk.lang}:`, sourceText);

          const sentAt = Date.now();
          const result = await this.sendWithRetry(chunk);

          if (result) {
            // Track latency (P7)
            const latency = Date.now() - sentAt;
            this.chunkLatencies.push(latency);
            if (this.chunkLatencies.length > 5) this.chunkLatencies.shift();
            const avg = this.chunkLatencies.reduce((a, b) => a + b, 0) / this.chunkLatencies.length;
            this.latencyDisplayEl.textContent = `~${(avg / 1000).toFixed(1)}s`;

            this.chunksSent++;
            this.chunksSentEl.textContent = this.chunksSent;

            // Show receiver status
            this.updateReceiverStatus(result.hasReceiver ? (result.accepted ? 'ok' : 'mismatch') : 'offline');

            // Check if visitor suggests a different preset (P3: auto-preset)
            if (result.suggestedPreset && result.suggestedPreset !== this.currentPreset) {
              console.log(`[Guide] Visitor suggests preset: ${result.suggestedPreset}`);
              this.applyPreset(result.suggestedPreset);
              const radio = document.querySelector(`input[name="preset"][value="${result.suggestedPreset}"]`);
              if (radio) radio.checked = true;
            }

            this.addToTranscript(sourceText);
            console.log(`[Guide] Sent. latency=${latency}ms hasReceiver=${result.hasReceiver}`);
          } else {
            // sendWithRetry returned null ‚Üí all retries failed
            this.updateReceiverStatus('error');
          }
        } catch (err) {
          console.error('[Guide] sendSourceText error:', err);
          this.updateReceiverStatus('error');
        }
      }

      updateReceiverStatus(status) {
        const icons = { ok: 'üü¢', mismatch: 'üü†', offline: 'üî¥', error: 'üî¥' };
        this.receiverStatusEl.textContent = icons[status] || 'üî¥';
      }

      // Network retry with exponential backoff (P8)
      async sendWithRetry(chunk, maxRetries = 3) {
        let delay = 1000;
        for (let i = 0; i < maxRetries; i++) {
          try {
            const response = await fetch('/ingest', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify(chunk)
            });

            // Check HTTP status before parsing JSON
            if (!response.ok) {
              const text = await response.text();
              console.warn(`[Guide] Server error ${response.status}:`, text.substring(0, 100));
              throw new Error(`HTTP ${response.status}`);
            }

            // Parse JSON with fallback for non-JSON responses (e.g. gateway HTML errors)
            let result;
            try {
              result = await response.json();
            } catch (jsonErr) {
              console.warn('[Guide] Risposta non-JSON dal server, assumo ok');
              result = { ok: true };
            }

            if (result.ok) return result;
            console.warn('[Guide] Chunk not accepted:', result);
            return null;
          } catch (err) {
            console.warn(`[Guide] Retry ${i + 1}/${maxRetries} dopo ${delay}ms:`, err.message);
            if (i < maxRetries - 1) {
              await new Promise(r => setTimeout(r, delay));
              delay *= 2;
            }
          }
        }
        console.error('[Guide] Chunk failed after retries, dropping');
        return null;
      }

      // ==========================================
      // WAKE LOCK
      // ==========================================

      async requestWakeLock() {
        if (!('wakeLock' in navigator)) {
          console.warn('[Guide] Wake Lock API not supported');
          return;
        }
        try {
          this.wakeLock = await navigator.wakeLock.request('screen');
          this.wakeLockBadge.style.display = '';
          this.wakeLock.addEventListener('release', () => {
            this.wakeLockBadge.style.display = 'none';
            this.wakeLock = null;
          });
          console.log('[Guide] Wake lock acquired');
        } catch (e) {
          console.warn('[Guide] Wake lock failed:', e);
        }
      }

      async releaseWakeLock() {
        if (this.wakeLock) {
          try { await this.wakeLock.release(); } catch (e) { /* already released */ }
          this.wakeLock = null;
          this.wakeLockBadge.style.display = 'none';
        }
      }

      // ==========================================
      // MICROPHONE SELECTION
      // ==========================================

      async enumerateMics() {
        try {
          // Request permission to get device labels
          const tempStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          tempStream.getTracks().forEach(t => t.stop());

          const devices = await navigator.mediaDevices.enumerateDevices();
          const mics = devices.filter(d => d.kind === 'audioinput');

          const saved = localStorage.getItem('voicetranslator_mic');
          this.micSelect.innerHTML = '<option value="">Default del sistema</option>';

          mics.forEach(mic => {
            const opt = document.createElement('option');
            opt.value = mic.deviceId;
            opt.textContent = mic.label || `Microfono ${mic.deviceId.substring(0, 8)}`;
            if (saved && saved === mic.deviceId) opt.selected = true;
            this.micSelect.appendChild(opt);
          });

          this.micSelect.onchange = () => {
            localStorage.setItem('voicetranslator_mic', this.micSelect.value);
          };

          console.log(`[Guide] Found ${mics.length} microphone(s)`);
        } catch (e) {
          console.warn('[Guide] Could not enumerate mics:', e);
        }
      }

      addToTranscript(text) {
        const p = document.createElement('p');
        p.textContent = text;
        this.transcriptLog.prepend(p);

        // Keep only last 10 items
        while (this.transcriptLog.children.length > 10) {
          this.transcriptLog.removeChild(this.transcriptLog.lastChild);
        }
      }

      updateStatus(state, text) {
        this.status.className = 'status ' + state;
        this.status.textContent = text;
      }

      muteAllAudio() {
        document.querySelectorAll('audio').forEach(audio => {
          audio.volume = 0;
          audio.muted = true;
          audio.pause();
        });
      }
    }

    // Initialize
    const guide = new GuideInput();
  </script>
</body>
</html>
